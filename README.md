# uber-data-and-prediction
Led a team of 7 students in analyzing a dataset of 600,000+ Uber & Lyft fares, aimed at creating a Python algorithm to predict Uber ride fares accurately.  Employed both linear least squares regression model and regression trees model, factoring in variables such as time of day, source, destination, surge multipliers, and Uber type.

Based on our analysis and comparing the results of the two models' predicted prices vs actual prices, our team found that the regression tree model produced more accurate fare predictions.

Project prepared by: Kenjee Koh, Jake Hudelson, Huy Bui, Anna Glushchenko, Lynn Hong, Sandy Huang, Thi Ngoc Tram Nguyen, Shuang Wu

Our full project report can be accessed here: [https://docs.google.com/document/d/1kR6W0bnoihzAJldTZK5uixUs1zelpSaigGkC1lXORH4/edit?usp=sharing](url)

____________________________________________________________________________________
## INTRODUCTION

Uber is a global application that provides ridesharing and delivery services for food and groceries, frequented by those who need quick, reliable transportation. Our project will concentrate on the ridesharing aspect of the service and gain insight to how its pricing model works.

As an affordable, reliable service and popular alternative to public transportation and traditional taxis all over the world, we believe the results we obtain will be meaningful to everyone who uses Uber, especially those who want to avoid surge pricing in advance.

Our main goal is to determine the best predictor(s) of ride fares that the Uber application generates from factors such as the time of day, distance traveled, surge multipliers, and Uber type (Uber X, Uber XL, Uber Black, Uber Black SUV, and Uber WAV). We also want to explore what kind of model can best estimate Uber fares based on the aforementioned factors. We will do so by utilizing two different models: linear least squares regression and a regression tree. This will be achieved by using different factors from a Kaggle dataset we found on Uber prices generated by Uber’s API to generate predicted fares, which will be compared to how much the actual fare would have been.

____________________________________________________________________________________
## RELATED WORKS

As discussed in class, we decided to use the statistical (linear least squares regression) and the machine learning (regression trees) model to predict the most accurate price that Uber uses to allocate its ride fares.

In the LLSR model, we use linear algebra operations to find predictive factors. This model fits for our project since the R-squared (R2) proportionately represents the variation in the outcome that is explained by the predictor variables. The R2 will correspond to the squared correlation between the observed outcome values (which is the price pulled from the data on Kaggle) and the predicted values by the model. We also follow the Decision Tree since this model searches for the descriptive feature in the dataset so we can split the target feature values most purely. We then can divide the dataset along the values of this descriptive feature, and we repeat this process for each of the sub datasets until we meet a stopping criterion. We grow a leaf node if a stopping requirement is met - in our case, it is expected to be the predicted fare rides.

We forecast that the LLSR will be more accurate than the Decision Tree model because we use multiple matrices from different columns to test for the prediction capabilities combined with each factor that we are generating from the model to compare the actual price with the predicted price.

____________________________________________________________________________________
## DATA GATHERING & PREPARATION

For this project, we originally intended to utilize Uber’s Ride Requests/Drivers API in order to create queries and extract real-time Uber data that we would feed into our models. That being said, however, we found out that Uber does not provide this data publicly, and so we had to come up with an alternative method of collecting the rider and fare data that we needed for this project.

Instead, we opted to utilize a dataset from the data science community platform Kaggle. This dataset titled “Uber & Lyft Cab Prices” by user ravimunde was generated to collect real-time data using Uber & Lyft API queries. Although this dataset’s data is not comprised of actual fares that occurred in the real-world, the data was generated to accurately mimic what real-world, real-time Uber & Lyft fares would cost like. With this in mind, this dataset was as accurate of a dataset as we can access. In addition, it is noted that this dataset is sampling Uber data only from Boston, Massachusetts. This means this sample will only be able to represent the Uber data in Boston rather than the entire population of the United States. Prices in Boston can only predict future prices in the area and may not show accurate prices compared to other cities such as New York, San Francisco, and Los Angeles, for instance.

The dataset measured all of the important factors in an Uber ride that we were interested in feeding into our models as factors. These factors are:
  1. Distance: The distance between source and destination measured in miles.
  2. Cab Type: Uber or Lyft (however we only used Ubers for this project)
  3. Time Stamp: Epoch time when data was queried
  4. Destination: Destination of the ride
  5. Source: The starting point of the ride
  6. Price: Price for the ride in USD
  7. Surge Multiplier: The multiplier by which price was increased (added to the         fare under special conditions such as days with low drivers, extreme weather        conditions, game days, etc)
  8. ID: Unique identifiers for each ride
  9. Product ID: Uber/Lyft identifier for Cab Type
  10. Name: Visible type of the cab (e.g. Uber Pool, UberXL, etc)

Our cleaning guidelines that we set for ourselves are as follows:
1. Create.
   
   We needed to create several dataframes to store:

   i. ALL cab data

   ii. "Sub Datasets" for each each type of fare (e.g. UberX, UberXL, etc).                We created these to account for cases where we were interested in
             analyzing each specific Uber type.

2. Delete.
   
   Delete rows we will not be using:

   i. ALL Lyfts. For the purpose of this project’s scope, we were only interested in Ubers.

   ii. Rows with any 0/empty values. These rows interfered with our model and caused errors.

3. Organize.
   
   Organize/reformat our data:

   i. Reset indexes. After the filters and modifications we made to the code, the indexes of our datapoints were inconsistent.

   ii. Convert timestamps & data types accordingly. Timestamps were included in our dataset, however they were formatted in an unconventional way that was not easy to read, so we had to reformat these to regular date & time formatting conventions. Furthermore, we had to make adjustments to the data types of various values (e.g. change numbers saved as str to float) in order to be able to feed these values into our models.
____________________________________________________________________________________
## EXPLORATORY ANALYSIS

For this project, we used two methods: one statistical (linear least squares regression) and one machine learning (regression trees). Data had to be prepared specifically for each model. However, both models shared the similarity that they receive an input of a set of at least two variables, and generate their best output. All variables were each stored identically in two separate locations, one as a list of numpy arrays and another as a numpy vector of numpy arrays, (effectively a matrix) with each method of storage designed for use in one of the models. A separate list was created to store a numerical list of integers incrementing by one for each variable (we had eight variables, so this list is stored as [0,1,2,3,4,5,6,7]). This list was used to generate combinations that would become inputs to the models. For example, an input might be (0,4,6), signifying that the first, fifth, and seventh variables (located in the zero, fourth, and sixth indexes, respectively, within each storage of the variables) were to be used for the input. Each method of variable storage allowed retrieval of variables by index, effectively allowing the combinatorial input to directly access the related variables.

The linear least squares regression (LLSR) algorithm is fed a set of inputs, and uses linear algebra operations (namely dot product) to find a solution. The algorithm operates strictly in matrices: rows represent individual rides, and columns represent variables. The variable storage used was the list of numpy arrays. At its core, this algorithm is linear: A * X = B (A times X equals B). “A” is a matrix of the variables we are using as inputs. “B” is a vector of actual ride prices generated by the Uber API. “X” is what the algorithm is trying to solve. The linear least squares regression algorithm generates an “X” such that when dot product is used to multiply “A” by “X”, a “B̂” is generated that is as close as possible to “B”. The program stores this “B̂” along with the inputs which generated its associated “X” value (“A”, or more efficiently the set of integer inputs representing the variables). The program also stores the mean absolute difference between “B̂” and “B”, giving each ride equal weight to the generated average difference between actual and predicted ride prices. As the combinatorial inputs generate new “X”s which create new “B̂”s, our program remembers the lowest mean absolute difference, along with the associated “B̂” and model input. Once all inputs have been tried, the program then has the most efficient efficiency: the algorithm generates the greatest efficiency given an input, and our program remembers the most efficient inputs. It took approximately 13 seconds to produce the variables that, when fed into the linear least squares regression algorithm, produce the lowest mean absolute difference.

The regression tree works similar to a decision tree, except that the output is not a binary option, it is a real number. To implement this in our program, we used “DecisionTreeRegressor” from the “sklearn.tree” library. We first had to create the model by declaration, passing a criterion that the model should minimize the mean square error. Next, we fit the model with the variable inputs and with the actual price of the rides. The variable storage used was the numpy vector of numpy arrays. Generating the predicted prices here required more work than with the linear least squares regression algorithm – that one used dot product to efficiently perform multiplication, whereas for the regression tree we had to manually go through each of the 330,568 rides to calculate the predicted prices. Predicted prices were generated by calling the .predict method on the model we earlier declared and fitted, passing in the same variables we fitted it with for the specific row we were operating on. As the predicted prices were being generated, preparations for calculating the mean absolute difference were being made; the difference between actual and predicted prices were being recorded and totaled, later divided after every row was iterated through. The program remembered the lowest mean absolute difference, along with the associated variable inputs and predicted price values. It took approximately 45 minutes to produce the variables that, when fed into the regression tree, produce the lowest mean absolute difference.

____________________________________________________________________________________
## DATA ANALYSIS

The predicted prices that both models generated were relatively similar, although the regression tree did better. It produced a mean absolute difference of $5.68, meaning that on average, the model predicted a price that was $5.68 away from the actual, true price generated by the Uber API. The regression tree used all eight variables to generate this best result: “Distance”, “Surge Multipliers”, “Is Uber X?”, “Is Uber XL?”, “Is Uber Black?”, “Is Uber Black SUV?”, and “Date (Hour) CMD”, meaning that no combination of variables could produce a better outcome through the regression tree than these eight variables. This also means all eight of these variables play some role in predicting the price of Uber rides within the regression tree model.

The linear least squares regression algorithm produced a mean absolute difference of $5.92, meaning that on average, the algorithm predicted a price that was $5.92 away from the actual, true price generated by the Uber API. It used five of the eight variables to generate its best result: “Distance”, “Surge Multipliers”, “Is Uber X?”, “Is Uber XL?”, and “Is Uber Black?”

The mean value of the true price generated by the Uber API was $15.80. This means the regression tree model and linear least squares regression algorithm predicted prices that were approximately 36% and 37% away from the true price, respectively. This deviation may be due to outliers that occur in our data. As shown in our presentation data points, many predictions from our linear regression and regression tree were close to the actual price; however, others predictions also were not within close range. These outliers highly skewed our approximation using the mean. Had our algorithm been utilizing the median instead, which is better when distribution of data values is skewed and there are lots of outliers, we would expect more efficient prediction.

After the Final Presentation, we tried to figure out the major impact of the surging price. At first, we focused on the uber price calculation based on uber fare information. Uber fare equation is (Base fare+Rate of total time taken+Rate of total distance covered)*(Surge Multiplier)+Tolls and other fees. For our database, we could ignore the surge multiplier, since all the surge multipliers are 1. According to Taxis-fare.com and Ridester.com, we could know the price calculation equation. Uber charges a ride depending on the amount of time the rider has spent in the car and the distance covered during the journey. The fare of Uber in Boston, in 2022 is like this. Uber will calculate the fare with base fare, distance fare unit, and time fare unit considering the distance and time. If the equation is lower than the minimum fare, Uber will charge the minimum fare.

According to our Dataframe, Boston’s 2017 minimum fare is $6. However, we could not know the distance fare unit and time fare unit. Considering those have not changed that much, we could estimate the price. To calculate the estimated fare following the equation, riding time is needed. The data frame only has timestamps, when the users had taken on, so we calculated the estimated time taken by figuring out longitude and latitude and calculating driving estimate time with Google Maps API. Comparing the real price and estimated price, this result shows more similarity, but hard to know about price surge because this data originally has no surging multiplier. Price surges when there are special events, rush hour, bad weather, etc. And the surges are at 1x multiple at normal demand but may result in higher multiples (1.5x, 2x), etc based on demand. This data was implausible to figure out how much or how surge pricing impacts the price, but was so meaningful that we can estimate the original price without the price surging and can figure out how much the price has surged compared to the expected uber price on-site. Due to the lack of surge prices, it is prospectable that the deviation of some of our data points may be due to surges in pricing.

Our project focuses primarily on the predictive side of data analytics rather than descriptive data analytics. Unfortunately, this data cannot be used universally due to the group graphical limitations of our data. However, external sources that utilized Uber API in its fullest are able to provide supplemental information about best practices to obtain the most efficient prices. In general, higher surges occur similarly to peak working hours, so it is encouraged to avoid taking rideshare during this time. This price may vary depending on location; for instance, in LA, peak working hours in the morning occur during 7:00 am to 8:00 am and end of the day from 4:00 pm to 6:00 pm while SF’s surge times are 7:00 am to 9:00 am and 5:00 pm to 7:00 pm	on weekdays. It is also cited that “The most common time for people to take an Uber on weekends is between 5:00 pm to 7:00 pm and 2:00 am. 2:00 am is the closing time for most drinking establishments in California.” 

In addition, surge prices also occur during large events: "The Giants won the World Series on Thursday, October 30th and a celebration parade ensued on Friday October 31st at noon. The parade ended around 2:00 pm, causing the surge multiplier to rise for approximately two hours.” Along with big events, we can also expect holidays (Halloween), festivals and concerts, bad weather conditions, and high trafficked areas such as the airport to carry particularly higher surge multipliers which consequently raise prices.

In all cities, Uber Black and Uber SUV rarely surge. When there is a surge in either of these products, both Uber Black and Uber SUV surge in unison and have the same multiplier, and when they do surge, both typically surge in unison and have the same multiplier. In particular, usage of Uber Black and Uber SUV is abundant in New York,  where it is used to commute home from work between the hours of 5:00 pm to 6:00 pm. The saying goes “New York truly doesn’t sleep,” and insights from the data proves this, as the surge multiplier in New York is almost always above 1.

Lastly, there are some recommendations for knowing this information. Beyond avoiding peak hours during general work hours and nightlife hours, adjusting your pin slightly for pickup and dropoff locations a few blocks away may decrease prices significantly during high traffic locations such as at the airport or concerts. On that note, places such as the airport may also charge convenience fees for picking up at their locations, and adjusting your pin in general will reduce prices from taking away this fee. Lastly, if surge prices are too high, waiting 30 minutes may reduce prices greatly.

____________________________________________________________________________________
## CONCLUSION

The LLSR might be the better choice if the relationship between data is linearity, or when there are a large number of features but less dataset. While in general, a Regression Tree will always have better accuracy since real-life data are mostly non-linearity. In our case, both the LLSR and Regression Tree predicted the price model, but the Regression Tree is always more accurate. Part of the reason would be that the Regression Tree takes more variables into account, and that minimizes the difference between the predicted price and the actual price. What is more important is that in addition to the well-known factors that affect Uber fares, such as source, destination, travel distance, surge multipliers, and Uber type, we found that the time of a day, specific and unique conditions can also greatly affect the price. For example, the price will be a little higher on days with terrible weather than on days with good weather for the same distance. Other influences would be specific events, like concerts or sporting events, and etc. With all those being said, even though we have successfully predicted the price model, there is still a 30% more difference. This has led us to learn how difficult and how complex the Machine Learning models that Uber's engineers have developed for the platform.
